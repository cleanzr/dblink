dblink : {

    // Define distortion hyperparameters (to be referenced below)
    lowDistortion : {alpha : 10.0, beta : 1000.0}

    // Define similarity functions (to be referenced below)
    constSimFn : {
        name : "ConstantSimilarityFn",
    }

    levSimFn : {
        name : "LevenshteinSimilarityFn",
        parameters : {
            threshold : 7.0
            maxSimilarity : 10.0
        }
    }

    data : {
        // Path to data files. Must have header row (column names).
        path : "./examples/RLdata10000.csv"

        // Specify columns that contain identifiers
        recordIdentifier : "rec_id",
        // fileIdentifier : null, // not needed since this data set is only a single file
        entityIdentifier : "ent_id" // optional

        // String representation of a missing value
        nullValue : "NA"

        // Specify properties of the attributes (columns) used for matching
        matchingAttributes : [
            {name : "by", similarityFunction : ${dblink.constSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "bm", similarityFunction : ${dblink.constSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "bd", similarityFunction : ${dblink.constSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "fname_c1", similarityFunction : ${dblink.levSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "lname_c1", similarityFunction : ${dblink.levSimFn}, distortionPrior : ${dblink.lowDistortion}}
        ]
    }

    randomSeed : 319158
    expectedMaxClusterSize : 10
    populationSize : 5000
    
    // Specify partitioner
    partitioner : {
        name : "KDTreePartitioner",
        parameters : {
            numLevels : 0, // a value of zero means no partitioning
            matchingAttributes : ["fname_c1"] // cycle through matching attributes in this order when constructing the tree
        }
    }

    // Path to Markov chain and full state (for resuming MCMC)
    outputPath : "./examples/RLdata10000_results/"

    // Path to save Spark checkpoints
    checkpointPath : "/tmp/spark_checkpoint/"
    
    // Steps to be performed (in order)
    steps : [
        {name : "sample", parameters : {
            sampleSize : 100,
            burninInterval : 0,
            thinningInterval : 10,
            resume : false,
            sampler : "PCG-I"
        }},
        {name : "summarize", parameters : {
            lowerIterationCutoff : 0,
            quantities : ["cluster-size-distribution", "partition-sizes"]
        }},
        {name : "evaluate", parameters : {
            lowerIterationCutoff : 100,
            metrics : ["pairwise", "cluster"], 
            useExistingSMPC : false
        }}
    ]
}
